{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 爬取专题\n",
    "- 同城\n",
    "- 明星\n",
    "- 搞笑\n",
    "- 游戏\n",
    "- 美妆\n",
    "- 美食\n",
    "- 摄影\n",
    "- 数码\n",
    "- 萌宠\n",
    "- 星座\n",
    "- 体育\n",
    "- 旅游\n",
    "- 教育\n",
    "- 国际\n",
    "- 财经\n",
    "- 婚恋\n",
    "- 时尚\n",
    "- 科技\n",
    "- 校园\n",
    "- 动漫"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 爬取数量\n",
    "- 爬取1200位用户\n",
    "- 每位用户爬取1000条数据，共360000条数据"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 隐藏身份\n",
    "\n",
    "- `Android`\n",
    "\n",
    "    - Mozilla/5.0 (Linux; Android 4.1.1; Nexus 7 Build/JRO03D) AppleWebKit/535.19 (KHTML, like Gecko) Chrome/18.0.1025.166 Safari/535.19\n",
    "    - Mozilla/5.0 (Linux; U; Android 4.0.4; en-gb; GT-I9300 Build/IMM76D) AppleWebKit/534.30 (KHTML, like Gecko) Version/4.0 Mobile Safari/534.30\n",
    "    - Mozilla/5.0 (Linux; U; Android 2.2; en-gb; GT-P1000 Build/FROYO) AppleWebKit/533.1 (KHTML, like Gecko) Version/4.0 Mobile Safari/533.1\n",
    "\n",
    "- `Firefox`\n",
    "\n",
    "    - Mozilla/5.0 (Windows NT 6.2; WOW64; rv:21.0) Gecko/20100101 Firefox/21.0\n",
    "    - Mozilla/5.0 (Android; Mobile; rv:14.0) Gecko/14.0 Firefox/14.0\n",
    "\n",
    "- `Google Chrome`\n",
    "\n",
    "    - Mozilla/5.0 (Windows NT 6.2; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/27.0.1453.94 Safari/537.36\n",
    "    - Mozilla/5.0 (Linux; Android 4.0.4; Galaxy Nexus Build/IMM76B) AppleWebKit/535.19 (KHTML, like Gecko) Chrome/18.0.1025.133 Mobile Safari/535.19\n",
    "\n",
    "- `iOS`\n",
    "\n",
    "    - Mozilla/5.0 (iPad; CPU OS 5_0 like Mac OS X) AppleWebKit/534.46 (KHTML, like Gecko) Version/5.1 Mobile/9A334 Safari/7534.48.3\n",
    "    - Mozilla/5.0 (iPod; U; CPU like Mac OS X; en) AppleWebKit/420.1 (KHTML, like Gecko) Version/3.0 Mobile/3A101a Safari/419.3"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Firefox设置IP代理\n",
    "\n",
    "```python\n",
    "    from selenium import webdriver\n",
    "\n",
    "    profile = webdriver.FirefoxProfile()\n",
    "\n",
    "    # 激活手动代理配置\n",
    "    profile.set_preference(\"network.proxy.type\", 1)\n",
    "    profile.set_preference(\"network.proxy.http\", HOST)\n",
    "    profile.set_preference(\"network.proxy.http_port\", PORT)\n",
    "\n",
    "    # 所有协议共用一种 ip 及端口，如果单独配置，不必设置该项，因为其默认为 False\n",
    "    profile.set_preference(\"network.proxy.share_proxy_settings\", True)\n",
    "\n",
    "    # 默认本地地址（localhost）不使用代理，如果有些域名在访问时不想使用代理可以使用类似下面的参数设置\n",
    "    # profile.set_preference(\"network.proxy.no_proxies_on\", \"localhost\")\n",
    "\n",
    "    profile.set_preference(\"general.useragent.override\", \"Mozilla/5.0 ...\")\n",
    "\n",
    "    driver = webdriver.Firefox(firefox_profile=profile)\n",
    "\n",
    "    driver.get(\"https://weibo.com\")\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 初始化环境"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 添加库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import traceback\n",
    "import openpyxl\n",
    "import requests\n",
    "import random\n",
    "import shutil\n",
    "import json\n",
    "import copy\n",
    "import os\n",
    "\n",
    "\n",
    "from tqdm import tqdm\n",
    "from time import sleep\n",
    "from scrapy import Selector\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 定义文件属性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_fields     =   ['uid',         '专题',             '头像',         '背景', \n",
    "                     '用户名',      '性别',             '会员等级',     '粉丝数', \n",
    "                     '关注数',      '全部微博',         '自我介绍',     '地域', \n",
    "                     'IP',          '加入微博时间',     '信用',         '出生日期/星座', \n",
    "                     'v认证',       '身份认证',         '表现',         '内容/IP机构认证',\n",
    "                     '校园',        '合作机构']\n",
    "\n",
    "\n",
    "follow_fields   =   ['follower_id', 'following_id',     '头像',         '背景', \n",
    "                     '用户名',      '性别',             '会员等级',     '粉丝数',   \n",
    "                     '关注数',      '全部微博',         '自我介绍',     '地域', \n",
    "                     'IP',          '加入微博时间',     '信用',         '出生日期/星座', \n",
    "                     'v认证',       '身份认证',         '表现',         '内容/IP机构认证', \n",
    "                     '校园',        '合作机构']\n",
    "\n",
    "\n",
    "weibo_fields    =   ['uid',             '日期',         '来源/设备',    '文本',\n",
    "                     '图片',            '转发数',       '评论数',       '点赞数',\n",
    "                     '是否转发',        '是否快转',     '是否点赞',     '原作者uid',    \n",
    "                     '原作者用户名',    '原发布日期',   '原设备',       '原文本',\n",
    "                     '原图片',          '原转发数',     '原评论数',     '原点赞数']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 构造文件结构"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spider_dir      = 'spider'\n",
    "graphs_dir      = 'spider/graphs'\n",
    "user_profiles   = 'spider/user_profiles.xlsx'\n",
    "follow_profiles = 'spider/follow_profiles.xlsx'\n",
    "weibo_profiles  = 'spider/weibo.xlsx'\n",
    "cookies_txt     = 'spider/cookies.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(spider_dir, mode=777)           if not os.path.exists(spider_dir)       else None\n",
    "os.makedirs(graphs_dir, mode=777)           if not os.path.exists(graphs_dir)       else None\n",
    "openpyxl.Workbook().save(user_profiles)     if not os.path.exists(user_profiles)    else None\n",
    "openpyxl.Workbook().save(follow_profiles)   if not os.path.exists(follow_profiles)  else None\n",
    "openpyxl.Workbook().save(weibo_profiles)    if not os.path.exists(weibo_profiles)   else None\n",
    "open(cookies_txt, 'w+').close()             if not os.path.exists(cookies_txt)      else None"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Excel追加内容"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_to_excel(path, lst):\n",
    "    target_book = openpyxl.load_workbook(path)\n",
    "    \n",
    "    for line in lst:\n",
    "        target_book.active.append(line)\n",
    "\n",
    "    target_book.save(path)\n",
    "    target_book.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 更新cookies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_cookies(path=cookies_txt):\n",
    "    driver = webdriver.Firefox()\n",
    "    driver.get('https://weibo.com/login.php')\n",
    "    while driver.current_url.find('https://weibo.com/login.php') == -1: sleep(3)\n",
    "    while driver.current_url.find('https://weibo.com/login.php') != -1: sleep(3)\n",
    "    sleep(3)\n",
    "    with open(path, 'w+', encoding='utf-8') as f: f.write(json.dumps(driver.get_cookies()))\n",
    "    driver.close()\n",
    "    driver.quit()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 配置cookies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置 cookies\n",
    "def set_cookies(driver, path=cookies_txt):\n",
    "    with open(path, 'r+', encoding='utf-8') as f: cookies = eval(f.read().replace('false', 'False').replace('true', 'True'))\n",
    "    for cookie in cookies:\n",
    "        conf = dict({   'domain'    :cookie['domain'], \n",
    "                        'name'      :cookie['name'], \n",
    "                        'value'     :cookie['value']}, \n",
    "                  **{   'expires'   :'', \n",
    "                        'path'      :'/', \n",
    "                        'httpOnly'  :False, \n",
    "                        'HostOnly'  :False, \n",
    "                        'Secure'    :False})\n",
    "        driver.add_cookie(conf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 定义函数、实现爬虫"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "'get_user_fields(driver, href)'\n",
    "```\n",
    "\n",
    "参数|说明\n",
    "----|----\n",
    "driver | 驱动对象\n",
    "href | 用户的主页链接\n",
    "说明 | 只适用于<a>https://weibo.com</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_user_fields(driver, href):\n",
    "\n",
    "    \"\"\"声明变量\"\"\"\n",
    "    avatar_url,     background_url,     username,       gender,                 \\\n",
    "    level,          followers,          followings,     weibo_count,            \\\n",
    "    introduction,   address,            ip,             join_date,              \\\n",
    "    credit,         birth,              v_auth,         id_auth,                \\\n",
    "    performance,    content_auth,       campus,         cooperative_org   =   [None]*20\n",
    "    \n",
    "    uid  = href.replace('https://weibo.com/u/', '')\n",
    "\n",
    "    # 进入用户主页\n",
    "    while driver.current_url != href:\n",
    "        try: driver.get(href); break\n",
    "        except: traceback\n",
    "\n",
    "        try: driver.get(random.choice(['https://weibo.com', 'https://weibo.com/at/weibo']))\n",
    "        except: traceback\n",
    "        sleep(random.randint(20, 60))\n",
    "\n",
    "\n",
    "    while True:\n",
    "        try: driver.find_element(By.XPATH, \"//i[@class='woo-font woo-font--angleDown']\").click(); break\n",
    "        except: traceback\n",
    "\n",
    "    response        = Selector(text=driver.page_source)\n",
    "\n",
    "    # 获取头像\n",
    "    avatar_url      = response.xpath(\"//div[@class='woo-panel-main woo-panel-top woo-panel-right woo-panel-bottom woo-panel-left Card_wrap_2ibWe Card_bottomGap_2Xjqi']//div[@class='woo-avatar-main woo-avatar-hover ProfileHeader_avatar2_1gEyo']/img/@src\").extract_first()\n",
    "    \n",
    "    # 获取背景\n",
    "    background_url  = response.xpath(\"//div[@class='woo-panel-main woo-panel-top woo-panel-right woo-panel-bottom woo-panel-left Card_wrap_2ibWe Card_bottomGap_2Xjqi']//div[@class='woo-picture-main ProfileHeader_pic_2Coeq']/img/@src\").extract_first()\n",
    "\n",
    "    # 获取用户名\n",
    "    username        = response.xpath(\"//div[@class='woo-panel-main woo-panel-top woo-panel-right woo-panel-bottom woo-panel-left Card_wrap_2ibWe Card_bottomGap_2Xjqi']//div[@class='ProfileHeader_name_1KbBs']/text()\").extract_first()\n",
    "\n",
    "    # 获取性别\n",
    "    gender          = 'female' if response.xpath(\"//div[@class='woo-panel-main woo-panel-top woo-panel-right woo-panel-bottom woo-panel-left Card_wrap_2ibWe Card_bottomGap_2Xjqi']//svg[@class='woo-icon-main woo-icon--female']\").extract_first() else 'male'\n",
    "\n",
    "    # 获取会员等级\n",
    "    level           = response.xpath(\"//div[@class='woo-panel-main woo-panel-top woo-panel-right woo-panel-bottom woo-panel-left Card_wrap_2ibWe Card_bottomGap_2Xjqi']//span[@class='woo-icon-wrap IconVip_icon_2tjdp']/@aria-label\").extract_first()\n",
    "\n",
    "    # 获取粉丝数\n",
    "    followers       = response.xpath(f\"//div[@class='woo-panel-main woo-panel-top woo-panel-right woo-panel-bottom woo-panel-left Card_wrap_2ibWe Card_bottomGap_2Xjqi']//a[@class='ALink_none_1w6rm ProfileHeader_alink_tjHJR ProfileHeader_pointer_2yKGQ' and @href='/u/page/follow/{uid}?relate=fans']/span/span/text()\").extract_first()\n",
    "    \n",
    "    # 获取关注数\n",
    "    followings      = response.xpath(f\"//div[@class='woo-panel-main woo-panel-top woo-panel-right woo-panel-bottom woo-panel-left Card_wrap_2ibWe Card_bottomGap_2Xjqi']//a[@class='ALink_none_1w6rm ProfileHeader_alink_tjHJR ProfileHeader_pointer_2yKGQ' and @href='/u/page/follow/{uid}?relate=']/span/span/text()\").extract_first()\n",
    "\n",
    "    # 获取全部微博数量\n",
    "    weibo_count     = response.xpath(\"//div[@class='wbpro-screen-v2 woo-box-flex woo-box-alignCenter woo-box-justifyBetween']/div/text()\").extract_first()\n",
    "\n",
    "    # 获取用户自我介绍\n",
    "    introduction    = response.xpath(\"//div[@class='woo-panel-main woo-panel-top woo-panel-right woo-panel-bottom woo-panel-left Card_wrap_2ibWe Card_bottomGap_2Xjqi']//i[@class='woo-font woo-font--proBintro']/../../div[@class='woo-box-item-flex ProfileHeader_con3_Bg19p']/text()\").extract_first()\n",
    "    \n",
    "    # 获取用户地域\n",
    "    address         = response.xpath(\"//div[@class='woo-panel-main woo-panel-top woo-panel-right woo-panel-bottom woo-panel-left Card_wrap_2ibWe Card_bottomGap_2Xjqi']//i[@class='woo-font woo-font--proPlace']/../../div[@class='woo-box-item-flex ProfileHeader_con3_Bg19p']/text()\").extract_first()\n",
    "\n",
    "    # 获取用户IP\n",
    "    ip              = response.xpath(\"//div[@class='woo-panel-main woo-panel-top woo-panel-right woo-panel-bottom woo-panel-left Card_wrap_2ibWe Card_bottomGap_2Xjqi']//i[@class='woo-font woo-font--ip']/../..//div[@class='woo-box-item-flex ProfileHeader_con3_Bg19p' and @style]/text()\").extract_first()\n",
    "\n",
    "    # 获取加入微博时间\n",
    "    join_date       = response.xpath(\"//div[@class='woo-panel-main woo-panel-top woo-panel-right woo-panel-bottom woo-panel-left Card_wrap_2ibWe Card_bottomGap_2Xjqi']//i[@class='woo-font woo-font--proTime']/../../div[@class='woo-box-item-flex ProfileHeader_con3_Bg19p']/text()\").extract_first()\n",
    "\n",
    "    # 获取用户信用\n",
    "    credit          = response.xpath(\"//div[@class='woo-panel-main woo-panel-top woo-panel-right woo-panel-bottom woo-panel-left Card_wrap_2ibWe Card_bottomGap_2Xjqi']//i[@class='woo-font woo-font--proCredit']/../../div[@class='woo-box-item-flex ProfileHeader_con3_Bg19p']/text()\").extract_first()\n",
    "\n",
    "    # 获取出生日期、星座\n",
    "    birth           = response.xpath(\"//div[@class='woo-panel-main woo-panel-top woo-panel-right woo-panel-bottom woo-panel-left Card_wrap_2ibWe Card_bottomGap_2Xjqi']//i[@class='woo-font woo-font--proIntro']/../../div[@class='woo-box-item-flex ProfileHeader_con3_Bg19p']/span/text()\").extract_first()\n",
    "\n",
    "    # 获取v认证\n",
    "    v_auth          = response.xpath(\"//div[@class='woo-panel-main woo-panel-top woo-panel-right woo-panel-bottom woo-panel-left Card_wrap_2ibWe Card_bottomGap_2Xjqi']//i[@class='woo-font woo-font--proV']/../../div[@class='woo-box-item-flex ProfileHeader_con3_Bg19p ProfileHeader_flexBasisAuto_2exBQ ProfileHeader_descText_3AF6o']/text()\").extract_first()\n",
    "\n",
    "    # 获取身份认证\n",
    "    id_auth         = response.xpath(\"//div[@class='woo-panel-main woo-panel-top woo-panel-right woo-panel-bottom woo-panel-left Card_wrap_2ibWe Card_bottomGap_2Xjqi']//span[@class='woo-icon-wrap woo-avatar-icon']/@title\").extract_first()\n",
    "\n",
    "    # 获取表现\n",
    "    performance     = '    '.join(response.xpath(\"//div[@class='woo-panel-main woo-panel-top woo-panel-right woo-panel-bottom woo-panel-left Card_wrap_2ibWe Card_bottomGap_2Xjqi']//div[@class='woo-box-flex woo-box-alignCenter woo-box-justifyBetween']/div/div/*/text()\").extract())\n",
    "\n",
    "    # 获取内容/IP机构认证\n",
    "    content_auth    = response.xpath(\"//div[@class='woo-panel-main woo-panel-top woo-panel-right woo-panel-bottom woo-panel-left Card_wrap_2ibWe Card_bottomGap_2Xjqi']//i[@class='woo-font woo-font--proCom']/../../div[@class='woo-box-item-flex ProfileHeader_con3_Bg19p']/text()\").extract_first()\n",
    "\n",
    "    # 获取校园\n",
    "    campus          = response.xpath(\"//div[@class='woo-panel-main woo-panel-top woo-panel-right woo-panel-bottom woo-panel-left Card_wrap_2ibWe Card_bottomGap_2Xjqi']//i[@class='woo-font woo-font--proEdu']/../../div[@class='woo-box-item-flex ProfileHeader_con3_Bg19p']/text()\").extract_first()\n",
    "\n",
    "    # 获取合作机构\n",
    "    cooperative_org = response.xpath(\"//div[@class='woo-panel-main woo-panel-top woo-panel-right woo-panel-bottom woo-panel-left Card_wrap_2ibWe Card_bottomGap_2Xjqi']//i[@class='woo-font woo-font--mcn']/../../div[@class='woo-box-item-flex ProfileHeader_con3_Bg19p']/text()\").extract_first()\n",
    "    \n",
    "    # 保存头像\n",
    "    with open(f\"{graphs_dir}/{uid}/avatar.jpg\", \"wb\") as file: \n",
    "        try:\n",
    "            WebDriverWait(driver, 0.15, 0.001).until(EC.presence_of_element_located((By.XPATH, \"//div[@class='woo-avatar-main woo-avatar-hover ProfileHeader_avatar2_1gEyo']/img\")))\n",
    "            avatar = driver.find_element(By.XPATH, \"//div[@class='woo-avatar-main woo-avatar-hover ProfileHeader_avatar2_1gEyo']/img\")\n",
    "            avatar_url = avatar.get_attribute('src')\n",
    "            content = requests.get(avatar_url).content\n",
    "            file.write(content);\n",
    "        except:\n",
    "            traceback\n",
    "    avatar_url      = f\"{graphs_dir}/{uid}/avatar.jpg\"\n",
    "\n",
    "    # 保存背景\n",
    "    with open(f\"{graphs_dir}/{uid}/background.jpg\", \"wb\") as file: \n",
    "        try:\n",
    "            WebDriverWait(driver, 0.15, 0.001).until(EC.presence_of_element_located((By.XPATH, \"//div[@class='woo-picture-main ProfileHeader_pic_2Coeq']/img\")))\n",
    "            background = driver.find_element(By.XPATH, \"//div[@class='woo-picture-main ProfileHeader_pic_2Coeq']/img\")\n",
    "            background_url = background.get_attribute('src')\n",
    "            content = requests.get(background_url).content\n",
    "            file.write(content)\n",
    "        except:\n",
    "            traceback\n",
    "    background_url  = f\"{graphs_dir}/{uid}/background.jpg\"\n",
    "\n",
    "    # 返回获取到用户的全部数据\n",
    "    return [avatar_url,     background_url,     username,       gender,         \n",
    "            level,          followers,          followings,     weibo_count,    \n",
    "            introduction,   address,            ip,             join_date,     \n",
    "            credit,         birth,              v_auth,         id_auth,       \n",
    "            performance,    content_auth,       campus,         cooperative_org]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "'get_weibo(driver, num)'\n",
    "```\n",
    "参数|说明\n",
    "--|--\n",
    "driver|浏览器驱动\n",
    "num|要爬取的微博数量\n",
    "说明 | 只适用于微博网页<a>https://weibo.com</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weibos(driver, href, num):\n",
    "\n",
    "    weibo_dic   =   list()\n",
    "\n",
    "    while driver.current_url != href:\n",
    "        try: driver.get(href); break\n",
    "        except: traceback\n",
    "        \n",
    "        try: driver.get(random.choice(['https://weibo.com', 'https://weibo.com/at/weibo']))\n",
    "        except: traceback\n",
    "        sleep(random.randint(20, 60))\n",
    "\n",
    "\n",
    "    for prog in tqdm(range(num), bar_format=href+' 微博数据爬取中:\\t{l_bar}{bar:30}{r_bar}'):\n",
    "\n",
    "        \"\"\"找到微博容器的列表\"\"\"\n",
    "        while True:\n",
    "            try:\n",
    "                WebDriverWait(driver, 0.3, 0.001).until(EC.presence_of_element_located((By.XPATH, \"//div[@class='vue-recycle-scroller__item-view']\")))\n",
    "                elements = [e for e in driver.find_elements(By.XPATH, \"//div[@class='vue-recycle-scroller__item-view']\") if e != None]\n",
    "                if elements: break\n",
    "            except: traceback\n",
    "\n",
    "        \"\"\"\n",
    "            遍历每一个容器、展开图片会改变当前位置\n",
    "            但是展开文本并不会、本次遍历目的是展开文本\n",
    "        \"\"\"\n",
    "        for elm in elements:\n",
    "            try:\n",
    "                WebDriverWait(driver, 0.15, 0.001).until(EC.presence_of_element_located((By.XPATH, \".//div[@class='detail_wbtext_4CRf9']//span\")))\n",
    "                more = [e for e in elm.find_elements(By.XPATH, \".//div[@class='detail_wbtext_4CRf9']//span\") if e.text == '展开' and e != None]\n",
    "                for e in more:\n",
    "                    try:    e.click();\n",
    "                    except: traceback\n",
    "            except: traceback\n",
    "\n",
    "        response = Selector(text=driver.page_source)\n",
    "\n",
    "        \"\"\"遍历每一个容器\"\"\"\n",
    "        for elm in response.xpath(\"//div[@class='vue-recycle-scroller__item-view']\"):\n",
    "\n",
    "            \"\"\"声明变量\"\"\"\n",
    "            uid,        date,           dev,            content,        img,                \\\n",
    "            fwd_count,  cmt_count,      lk_count,       is_fwd,         is_fast_fwd,        \\\n",
    "            is_like,    src_uid,        src_uname,      src_date,       src_dev,            \\\n",
    "            src_cont,   src_img,        src_fwd_count,  src_cmt_count,  src_lk_count    =   [None]*20\n",
    "            \n",
    "            uid         = href.replace('https://weibo.com/u/', '')\n",
    "            is_fwd      = False\n",
    "            is_fast_fwd = False\n",
    "            is_like     = False\n",
    "            add_img_src = None\n",
    "            img_srcs    = set()\n",
    "\n",
    "            src_wb      = elm.xpath(\".//div[@class='Feed_retweet_JqZJb']\")\n",
    "            \"\"\"********************************************************************************************************************************\"\"\"            \n",
    "            \"\"\"判断是否为转发微博\"\"\"\n",
    "            if  src_wb:\n",
    "                is_fwd      = True\n",
    "\n",
    "            \"\"\"判断是否为快转的微博\"\"\"\n",
    "            if elm.xpath(\".//span[@class='head_fastbehind_1StRl']\").extract(): \n",
    "                is_fast_fwd = True\n",
    "\n",
    "            \"\"\"判断是否为点赞的微博\"\"\"\n",
    "            if elm.xpath(\".//span[@class='title_title_1DVuO']\").extract() and not elm.xpath(\".//span[@class='title_title_1DVuO']/img\").extract():\n",
    "                is_like     = True\n",
    "                is_fwd      = False\n",
    "\n",
    "            \"\"\"图片\"\"\"\n",
    "            img_srcs = img_srcs | set(elm.xpath(\".//div[@class='picture picture-box_row_30Iwo']//img/@src\").extract())\n",
    "\n",
    "            \"\"\"\"创建目录\"\"\"\n",
    "            shutil.rmtree(f\"{graphs_dir}/{uid}/{len(weibo_dic)}\")           if     os.path.exists(f\"{graphs_dir}/{uid}/{len(weibo_dic)}\") else None\n",
    "            os.makedirs  (f\"{graphs_dir}/{uid}/{len(weibo_dic)}\", mode=777) if not os.path.exists(f\"{graphs_dir}/{uid}/{len(weibo_dic)}\") else None\n",
    "\n",
    "            \"\"\"根据不同类型的微博给变量赋值****************************************************************************************************************\"\"\"\n",
    "            if is_fwd:\n",
    "                src_uid     = src_wb.xpath(\".//a[@class='ALink_default_2ibt1']/@href\").extract_first()\n",
    "\n",
    "                if not src_uid:\n",
    "                    src_uid = src_wb.xpath(\".//a[@class='router-link-exact-active router-link-active ALink_default_2ibt1']/@href\").extract_first()\n",
    "                    \n",
    "                if src_uid:\n",
    "                    src_uid = src_uid.replace('https://weibo.com/u/', '').replace('/u/', '')\n",
    "\n",
    "                src_uname   = src_wb.xpath(\".//span[@class='detail_nick_u-ffy']/text()\").extract_first()\n",
    "\n",
    "                if src_uname:\n",
    "                    src_uname = src_uname.replace('@', '')\n",
    "                \n",
    "                src_date    = src_wb.xpath(\".//a[@class='head-info_time_6sFQg']/@title\").extract_first()\n",
    "\n",
    "                src_cont    = '    '.join(src_wb.xpath(\".//div[@class='detail_wbtext_4CRf9']/text()\").extract()).replace('\\n', '    ')\n",
    "\n",
    "                src_img     = f\"{graphs_dir}/{uid}/{len(weibo_dic)}\"\n",
    "\n",
    "                add_img_src = elm.xpath(\".//div[@class='detail_wbtext_4CRf9']/a[@target='_blank']/@href\").extract_first()\n",
    "\n",
    "                img         = f\"{graphs_dir}/{uid}/{len(weibo_dic)}_addition\"\n",
    "\n",
    "                date        = elm.xpath(\".//header/div/div/div/a[@class='head-info_time_6sFQg']/@title\").extract_first()\n",
    "\n",
    "                dev         = elm.xpath(\".//div[@class='head-info_cut_1tPQI head-info_source_2zcEX']/text()\").extract_first()\n",
    "\n",
    "                other_dev   = [text for text in elm.xpath(\".//div[@class='head-info_cut_1tPQI head-info_source_2zcEX']//*/text()\").extract() if text != None and text != '']\n",
    "                \n",
    "                if other_dev:\n",
    "                    dev     = dev + ' ' + ' '.join(other_dev)\n",
    "\n",
    "                content     = '    '.join(elm.xpath(\".//article//div[@class='detail_text_1U10O detail_ogText_2Z1Q8 wbpro-feed-ogText']//div[@class='detail_wbtext_4CRf9']/text()\").extract()).replace('\\n', '    ')\n",
    "\n",
    "                line        = src_wb.xpath(\".//footer/@aria-label\").extract_first()\n",
    "                \n",
    "                if line:\n",
    "                    src_fwd_count, src_cmt_count, src_lk_count = line.split(',')\n",
    "\n",
    "                line        = elm.xpath(\".//article/footer/@aria-label\").extract_first()\n",
    "\n",
    "                if line:\n",
    "                    fwd_count,     cmt_count,     lk_count     = line.split(',')\n",
    "                 \n",
    "            # ***************************************************************************************************************************\n",
    "            elif is_like or is_fast_fwd:\n",
    "                src_uid     = elm.xpath(\".//a[@class='ALink_default_2ibt1']/@href\").extract_first()\n",
    "\n",
    "                if src_uid:\n",
    "                    src_uid = src_uid.replace('https://weibo.com/u/', '').replace('/u/', '')\n",
    "\n",
    "                src_uname   = elm.xpath(\".//a[@class='ALink_default_2ibt1']/@aria-label\").extract_first()\n",
    "\n",
    "                if src_uname:\n",
    "                    src_uname = src_uname.replace('@', '')\n",
    "\n",
    "                src_date    = elm.xpath(\".//header/div/div/div/a[@class='head-info_time_6sFQg']/@title\").extract_first()\n",
    "\n",
    "                if is_like:\n",
    "                    date    = elm.xpath(\".//span[@class='title_title_1DVuO']/text()\").extract_first()\n",
    "\n",
    "                src_dev     = elm.xpath(\".//div[@class='head-info_cut_1tPQI head-info_source_2zcEX']/text()\").extract_first()\n",
    "\n",
    "                other_dev   = [text for text in elm.xpath(\".//div[@class='head-info_cut_1tPQI head-info_source_2zcEX']//*/text()\").extract() if text != None and text != '']\n",
    "                \n",
    "                if other_dev:\n",
    "                    src_dev = src_dev + ' ' + ' '.join(other_dev)\n",
    "                \n",
    "                src_cont    = '    '.join(elm.xpath(\".//article//div[@class='detail_text_1U10O detail_ogText_2Z1Q8 wbpro-feed-ogText']//div[@class='detail_wbtext_4CRf9']/text()\").extract()).replace('\\n', '    ')\n",
    "\n",
    "                src_img     = f\"{graphs_dir}/{uid}/{len(weibo_dic)}\"\n",
    "\n",
    "                line        = elm.xpath(\".//article/footer/@aria-label\").extract_first()\n",
    "\n",
    "                if is_like and line:\n",
    "                    src_fwd_count, src_cmt_count, src_lk_count = line.split(',')\n",
    "\n",
    "                elif line:\n",
    "                    fwd_count,     cmt_count,     lk_count     = line.split(\",\")\n",
    "                \n",
    "            # ***********************************************************************************************************************\n",
    "            else:     \n",
    "                date        = elm.xpath(\".//header/div/div/div/a[@class='head-info_time_6sFQg']/@title\").extract_first()\n",
    "\n",
    "                dev         = elm.xpath(\".//div[@class='head-info_cut_1tPQI head-info_source_2zcEX']/text()\").extract_first()\n",
    "\n",
    "                other_dev   = [text for text in elm.xpath(\".//div[@class='head-info_cut_1tPQI head-info_source_2zcEX']//*/text()\").extract() if text != None and text != '']\n",
    "                \n",
    "                if other_dev:\n",
    "                    dev     = dev + ' ' + ' '.join(other_dev)\n",
    "\n",
    "                content     = '    '.join(elm.xpath(\".//article//div[@class='detail_text_1U10O detail_ogText_2Z1Q8 wbpro-feed-ogText']//div[@class='detail_wbtext_4CRf9']/text()\").extract()).replace('\\n', '    ')\n",
    "\n",
    "                img = f\"{graphs_dir}/{uid}/{len(weibo_dic)}\"\n",
    "                \n",
    "                line        = elm.xpath(\".//article/footer/@aria-label\").extract_first()\n",
    "\n",
    "                if line:\n",
    "                    fwd_count, cmt_count, lk_count = line.split(',')\n",
    "\n",
    "            \"\"\"**************************************************************************************************************************\"\"\"\n",
    "            \"\"\"添加数据\"\"\"\n",
    "            data_dic = {'uid'           :uid,\n",
    "                        'date'          :date,\n",
    "                        'dev'           :dev,\n",
    "                        'content'       :content,\n",
    "                        'img'           :img,\n",
    "                        'fwd_count'     :fwd_count,\n",
    "                        'cmt_count'     :cmt_count,\n",
    "                        'lk_count'      :lk_count,\n",
    "                        'is_fwd'        :is_fwd,\n",
    "                        'is_fast_fwd'   :is_fast_fwd,\n",
    "                        'is_like'       :is_like,\n",
    "                        'src_uid'       :src_uid,\n",
    "                        'src_uname'     :src_uname,\n",
    "                        'src_date'      :src_date,\n",
    "                        'src_dev'       :src_dev,\n",
    "                        'src_cont'      :src_cont,\n",
    "                        'src_img'       :src_img,\n",
    "                        'src_fwd_count' :src_fwd_count,\n",
    "                        'src_cmt_count' :src_cmt_count,\n",
    "                        'src_lk_count'  :src_lk_count}\n",
    "\n",
    "            can_add = True if '' not in list(data_dic.values()) else False\n",
    "\n",
    "            if can_add:\n",
    "                for dic in copy.deepcopy(weibo_dic):\n",
    "                    dt_dic_cp = copy.deepcopy(data_dic)\n",
    "                    dt_dic_cp.pop('img')\n",
    "                    dt_dic_cp.pop('src_img')\n",
    "                    dic.pop('img')\n",
    "                    dic.pop('src_img')\n",
    "                    can_add = True if list(dic.values()) != list(dt_dic_cp.values()) else False\n",
    "                    if not can_add: break\n",
    "                    \n",
    "            if  can_add:\n",
    "                for index, src in enumerate(img_srcs):\n",
    "                    with open(f\"{graphs_dir}/{uid}/{len(weibo_dic)}/{index}.jpg\", 'wb') as file:\n",
    "                        try: file.write(requests.get(src).content)\n",
    "                        except: traceback\n",
    "                \n",
    "                if is_fwd and img and add_img_src:\n",
    "                    shutil.rmtree(img)  if     os.path.exists(img)  else None\n",
    "                    os.makedirs(img)    if not os.path.exists(img)  else None\n",
    "                    with open(f\"{img}/addition.jpg\", 'wb') as file:\n",
    "                        try: file.write(requests.get(add_img_src).content)\n",
    "                        except: traceback\n",
    "\n",
    "                weibo_dic.append(data_dic)\n",
    "            \n",
    "        \"\"\"向下滚动900px\"\"\"\n",
    "        driver.execute_script(\"window.scrollBy(0, 1080);\")\n",
    "\n",
    "    return [list(dic.values()) for dic in weibo_dic]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "'crawling(driver, lanbel, num)'\n",
    "```\n",
    "参数|说明\n",
    "---|---\n",
    "driver | 浏览器驱动\n",
    "label | 要爬取的标签\n",
    "num | 要在当前专题下爬取的人数\n",
    "说明 | 只适用于微博网页<a>https://weibo.com</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crawling(driver, label, num=60):\n",
    "\n",
    "    usr_href_set = set()\n",
    "\n",
    "    try:\n",
    "        WebDriverWait(driver, 1.5, 0.001).until(EC.presence_of_element_located((By.XPATH, \"//div[@class='woo-box-flex woo-box-alignCenter woo-box-justifyCenter Ctrls_item_3KzNH' and @title='热门']\")))\n",
    "        driver.find_element(By.XPATH, \"//div[@class='woo-box-flex woo-box-alignCenter woo-box-justifyCenter Ctrls_item_3KzNH' and @title='热门']\").click()\n",
    "    except:\n",
    "        traceback\n",
    "\n",
    "    try:\n",
    "        WebDriverWait(driver, 1.5, 0.001).until(EC.presence_of_element_located((By.XPATH, \"//i[@class='woo-font woo-font--more' and @title='更多']\")))\n",
    "        driver.find_element(By.XPATH, \"//i[@class='woo-font woo-font--more' and @title='更多']\").click()\n",
    "    except:\n",
    "        traceback\n",
    "\n",
    "    # 找到多个专题、然后点击名称为label的专题\n",
    "    while True:\n",
    "        sleep(0.15)\n",
    "        try:\n",
    "            e = [e for e in driver.find_elements(By.XPATH,  \"//div[@class='wbpro-textcut']\") if e.text==label and e!=None].pop()\n",
    "            e.click(); break\n",
    "        except: \n",
    "            traceback\n",
    "\n",
    "    # 持续向下滚动、扫描到num个用户的主页href则停止\n",
    "    while len(usr_href_set) < num:\n",
    "        sleep(0.15)\n",
    "        try:\n",
    "            usr_href_set = usr_href_set | {item.get_attribute('href') for item in driver.find_elements(By.XPATH, \"//a[@class='ALink_default_2ibt1 head_cut_2Zcft head_name_24eEB']\") if item.text!=''}\n",
    "            driver.execute_script(\"window.scrollBy(0, 360);\")\n",
    "        except:\n",
    "            traceback\n",
    "        while len(usr_href_set) > num: usr_href_set.pop()\n",
    "\n",
    "    \"\"\"\"******************************************************************************************************************************************\"\"\"\n",
    "    \"\"\"遍历每一位user_href_set里的用户\"\"\"\n",
    "    for href in usr_href_set:\n",
    "        uid             = href.replace('https://weibo.com/u/', '')\n",
    "        follow_href_set = set()\n",
    "        follow          = None\n",
    "        num             = None\n",
    "\n",
    "        # 先进入用户主页\n",
    "        while driver.current_url != href:\n",
    "            try: driver.get(href); break\n",
    "            except: traceback\n",
    "            \n",
    "            try: driver.get(random.choice(['https://weibo.com', 'https://weibo.com/at/weibo']))\n",
    "            except: traceback\n",
    "            sleep(random.randint(20, 60))\n",
    "        \n",
    "        # 关注此用户\n",
    "        while True:\n",
    "            try:\n",
    "                WebDriverWait(driver, 1.5, 0.001).until(EC.presence_of_element_located((By.XPATH, \"//button[@class='woo-button-main woo-button-flat woo-button-primary woo-button-m woo-button-round FollowBtn_m_1UJhp ProfileHeader_btn3_2VD_Y']\")))\n",
    "                driver.find_element(By.XPATH, \"//button[@class='woo-button-main woo-button-flat woo-button-primary woo-button-m woo-button-round FollowBtn_m_1UJhp ProfileHeader_btn3_2VD_Y']\").click()\n",
    "                sleep(0.6)\n",
    "                break\n",
    "            except:\n",
    "                traceback\n",
    "        \n",
    "        # 获取关注数\n",
    "        while follow in {None, ''}:\n",
    "            follow = Selector(text=driver.page_source).xpath(\"//div[@class='woo-box-flex woo-box-alignCenter ProfileHeader_h4_gcwJi']/a[@class='ALink_none_1w6rm ProfileHeader_alink_tjHJR ProfileHeader_pointer_2yKGQ']/span/span/text()\").extract_first()\n",
    "\n",
    "        if  follow.isdigit():\n",
    "            follow = 250 if int(follow) > 250 else int(follow)\n",
    "        else:\n",
    "            follow = 250\n",
    "\n",
    "        # 获取微博数量\n",
    "        while num in {None, ''}:\n",
    "            num = Selector(text=driver.page_source).xpath(\"//div[@class='wbpro-screen-v2 woo-box-flex woo-box-alignCenter woo-box-justifyBetween']/div/text()\").extract_first()\n",
    "        \n",
    "        num     = int(''.join([c for c in num if c.isdigit()]))\n",
    "        num     = 1000 if num > 1000 else num\n",
    "\n",
    "        # 进入用户的关注主页\n",
    "        while True:\n",
    "            try:\n",
    "                driver.find_element(By.XPATH, \"//div[@class='woo-box-flex woo-box-alignCenter ProfileHeader_h4_gcwJi']/a[@class='ALink_none_1w6rm ProfileHeader_alink_tjHJR ProfileHeader_pointer_2yKGQ']\").click()\n",
    "                break\n",
    "            except:\n",
    "                traceback\n",
    "            \n",
    "        sleep(0.6)\n",
    "\n",
    "        # 获取到当前用户的所有关注的主页面链接\n",
    "        while follow > 0:\n",
    "            try:\n",
    "                follow_href_set = follow_href_set | {item.get_attribute('href') for item in driver.find_elements(By.XPATH, \"//a[@class='ALink_none_1w6rm UserCard_item_TrVS0']\")}\n",
    "                driver.execute_script(\"window.scrollBy(0, 188);\")\n",
    "            except:\n",
    "                traceback\n",
    "            follow -= 2\n",
    "\n",
    "        # 新建用户保存图片的目录\n",
    "        for item in {href} | follow_href_set:\n",
    "            dir_path = graphs_dir + '/' + item.replace('https://weibo.com/u/', '')\n",
    "            os.makedirs(dir_path) if not os.path.exists(dir_path) else None\n",
    "\n",
    "        # 添加用户自身的数据\n",
    "        add_to_excel(user_profiles, [[uid, label] + get_user_fields(driver, href)])\n",
    "\n",
    "        # 添加用户的微博数据\n",
    "        add_to_excel(weibo_profiles, get_weibos(driver, href, num))\n",
    "\n",
    "        driver.execute_script(\"window.scrollTo(0, 0);\")\n",
    "        sleep(1.5)\n",
    "\n",
    "        # 鼠标悬停到已关注button上\n",
    "        try:\n",
    "            WebDriverWait(driver, 3.0, 0.001).until(EC.presence_of_element_located((By.XPATH, \"//button[@class='woo-button-main woo-button-line woo-button-default woo-button-m woo-button-round FollowBtn_m_1UJhp ProfileHeader_btn3_2VD_Y']\")))\n",
    "            element = driver.find_element(By.XPATH, \"//button[@class='woo-button-main woo-button-line woo-button-default woo-button-m woo-button-round FollowBtn_m_1UJhp ProfileHeader_btn3_2VD_Y']\")\n",
    "            ActionChains(driver).move_to_element(element).perform()\n",
    "        except:\n",
    "            traceback\n",
    "\n",
    "        # 点击取消关注\n",
    "        try:\n",
    "            WebDriverWait(driver, 3.0, 0.001).until(EC.presence_of_element_located((By.XPATH, \"//div[@class='woo-box-flex woo-box-alignCenter woo-pop-item-main FollowPop_item_1GgQ0' and @role='button']\")))\n",
    "            elements = driver.find_elements(By.XPATH, \"//div[@class='woo-box-flex woo-box-alignCenter woo-pop-item-main FollowPop_item_1GgQ0' and @role='button']\")\n",
    "            [e.click() for e in elements if '取消关注' in e.text]\n",
    "        except:\n",
    "            traceback\n",
    "\n",
    "        # 确认\n",
    "        try:\n",
    "            WebDriverWait(driver, 3.0, 0.001).until(EC.presence_of_element_located((By.XPATH, \"//button[@class='woo-button-main woo-button-flat woo-button-primary woo-button-m woo-button-round woo-dialog-btn']\")))\n",
    "            element = driver.find_element(By.XPATH, \"//button[@class='woo-button-main woo-button-flat woo-button-primary woo-button-m woo-button-round woo-dialog-btn']\")\n",
    "            element.click()\n",
    "        except:\n",
    "            traceback\n",
    "\n",
    "        while True:\n",
    "            sleep(0.6)\n",
    "            try: driver.find_element(By.XPATH, \"//div[@class='woo-box-flex woo-box-column woo-box-alignCenter woo-box-justifyCenter woo-toast-main woo-toast--success']/div[@class='woo-toast-body']/span[text()='取关成功']\")\n",
    "            except: traceback; break\n",
    "        \n",
    "        # 遍历获取到的链接、拿到此用户关注的每一位用户的基本数据\n",
    "        temp_data_lst = list()\n",
    "        for prog in tqdm(range(len(follow_href_set)), bar_format=href+' 用户关注爬取中:\\t{l_bar}{bar:30}{r_bar}'):\n",
    "            item = follow_href_set.pop()\n",
    "            temp_data_lst.append([uid, item.replace('https://weibo.com/u/', '')] + get_user_fields(driver, item))\n",
    "\n",
    "        add_to_excel(follow_profiles, temp_data_lst)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 执行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "\n",
    "    # 添加xlsx文件属性\n",
    "    for item in [(user_profiles,user_fields), (follow_profiles,follow_fields), (weibo_profiles,weibo_fields)]:\n",
    "        path, cont = item\n",
    "        book       = openpyxl.load_workbook(path)\n",
    "        sheet      = book.active\n",
    "\n",
    "        if sheet.max_row == 1 and sheet.max_column == 1: \n",
    "            add_to_excel(path, [cont])\n",
    "\n",
    "    # 设置标签\n",
    "    labels = ['艺术', '明星', '动漫', '搞笑', '游戏', \n",
    "              '美妆', '美食', '摄影', '数码', '萌宠', \n",
    "              '星座', '体育', '旅游', '教育', '国际', \n",
    "              '财经', '婚恋', '时尚', '科技', '校园']\n",
    "\n",
    "    # 更新cookies\n",
    "    with open(cookies_txt, 'r+') as file:\n",
    "        if len(file.readlines()) == 0:  \n",
    "            update_cookies(cookies_txt)\n",
    "\n",
    "    # 创建 FirefoxOptions 对象，设置无头模式和允许加载图片\n",
    "    options             = webdriver.FirefoxOptions()\n",
    "    options.headless    = True\n",
    "    options.set_preference(\"permissions.default.image\", 0)\n",
    "\n",
    "    driver = webdriver.Firefox(options=options)\n",
    "\n",
    "    sleep(5)\n",
    "\n",
    "    # 进入登录界面\n",
    "    driver.get('https://weibo.com/login.php')\n",
    "\n",
    "    # 等待登录成功\n",
    "    while driver.current_url.find('https://weibo.com/login.php') == -1: sleep(3)\n",
    "\n",
    "    # 设置cookies\n",
    "    while True:\n",
    "        sleep(3);       set_cookies(driver, cookies_txt)\n",
    "        sleep(1);       driver.refresh()    \n",
    "        sleep(3);\n",
    "\n",
    "        if  driver.current_url.find('https://weibo.com/login.php') != -1:\n",
    "            update_cookies(cookies_txt)\n",
    "\n",
    "        else: break\n",
    "\n",
    "\n",
    "    # 爬虫主程序\n",
    "    while True:\n",
    "        operation = input('\\n是否爬虫(yes or no):\\t')\n",
    "\n",
    "        if operation in {'y', 'Y', 'yes', 'YES'}:\n",
    "            driver.set_page_load_timeout(10)\n",
    "            titles = list()\n",
    "            num    = 0\n",
    "\n",
    "            for index, topic in enumerate(labels, start=1):\n",
    "                print(topic, end='\\n', flush=True) if index % 5 == 0 else print(topic, end='\\t', flush=True)\n",
    "                \n",
    "            while True:\n",
    "                for title in input('输入要爬取的专题(以空格分隔):\\t').split(' '):\n",
    "                    titles.append(title) if title in labels else print(f'{title}不在专题范围内', flush=True)\n",
    "\n",
    "                if len(titles) > 0: break\n",
    "                \n",
    "                print('没有匹配项', flush=True)\n",
    "\n",
    "\n",
    "            while True:\n",
    "                num = input('输入要爬取的人数(请输入大于0的整数):\\t')\n",
    "                if not num.isdigit(): print('请输入大于0的整数', flush=True)\n",
    "                elif int(num) <= 0: print('请输入大于0的整数', flush=True)\n",
    "                else: num = int(num); break\n",
    "            \n",
    "            for title in titles:\n",
    "                crawling(driver, title, num)\n",
    "\n",
    "            print('爬取完毕', flush=True)\n",
    "\n",
    "        elif operation in {'n', 'N', 'no', 'NO'}: break\n",
    "        else: print('指令错误', flush=True)\n",
    "\n",
    "    # 关闭爬虫程序\n",
    "    driver.close()\n",
    "    driver.quit()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 打包程序\n",
    "- pip install pyinstaller\n",
    "- pyinstaller -F --hidden-import=openpyxl.cell._writer  file_name"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `Test`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 添加xlsx文件属性\n",
    "# for item in [(user_profiles,user_fields), (follow_profiles,follow_fields), (weibo_profiles,weibo_fields)]:\n",
    "#     path, cont = item\n",
    "#     book       = openpyxl.load_workbook(path)\n",
    "#     sheet      = book.active\n",
    "\n",
    "#     if sheet.max_row == 1 and sheet.max_column == 1: \n",
    "#         add_to_excel(path, [cont])\n",
    "\n",
    "# # 设置标签\n",
    "# labels = ['艺术', '明星', '动漫', '搞笑', '游戏', \n",
    "#           '美妆', '美食', '摄影', '数码', '萌宠', \n",
    "#           '星座', '体育', '旅游', '教育', '国际', \n",
    "#           '财经', '婚恋', '时尚', '科技', '校园']\n",
    "\n",
    "# # 更新cookies\n",
    "# with open(cookies_txt, 'r+') as file:\n",
    "#     if len(file.readlines()) == 0:  \n",
    "#         update_cookies(cookies_txt)\n",
    "\n",
    "# driver = webdriver.Firefox()\n",
    "\n",
    "# # 进入登录界面\n",
    "# driver.get('https://weibo.com/login.php')\n",
    "\n",
    "# # 等待登录成功\n",
    "# while driver.current_url.find('https://weibo.com/login.php') == -1: sleep(3)\n",
    "\n",
    "# # 设置cookies\n",
    "# while True:\n",
    "#     sleep(3);       set_cookies(driver, cookies_txt)\n",
    "#     sleep(1);       driver.refresh()    \n",
    "#     sleep(3);\n",
    "\n",
    "#     if  driver.current_url.find('https://weibo.com/login.php') != -1:\n",
    "#         update_cookies(cookies_txt)\n",
    "\n",
    "#     else: break\n",
    "\n",
    "# crawling(driver, '美妆', 2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
